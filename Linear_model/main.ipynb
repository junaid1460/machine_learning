{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data and fix errors\n",
    "the data read has some minor errors like string 'false' instead of boolean False\n",
    "let's fix them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#read training data set\n",
    "\n",
    "def read_train_data():\n",
    "    return pd.read_csv('./train.csv')\n",
    "# normalize column values\n",
    "def fix_errors(data):\n",
    "    data['disable_communication'] = data['disable_communication'].replace(['false'],False)\n",
    "    data['disable_communication'] = data['disable_communication'].replace(['true'],True)\n",
    "    print('replaced \\'false\\' with False and \\'true\\' with True') \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#exchange rates from yahoo\n",
    "\n",
    "def read_exchange_rates_json():\n",
    "    url = 'https://finance.yahoo.com/webservice/v1/symbols/allcurrencies/quote?format=json'\n",
    "    try:\n",
    "        return pd.read_json(io.StringIO(requests.get(url).content.decode('utf-8')))['list']['resources']\n",
    "    except:\n",
    "        print('couldn\\'t fetch data from yahoo, loading local data')\n",
    "        return pd.read_json('./currencyrates.json')['list']['resources']\n",
    "        \n",
    "\n",
    "# make dictionary of required field\n",
    "def get_exchange_rates_dataframe(data):\n",
    "    rates = []\n",
    "    for rate in data:\n",
    "        dt = rate['resource']['fields']\n",
    "        name = dt['name']\n",
    "        if(name[0:3]!='USD'):\n",
    "            continue\n",
    "            \n",
    "        if(len(name) < 6):\n",
    "            rates = rates + [{'to':name,'price' : float(dt['price'])  }]\n",
    "            continue\n",
    "            \n",
    "        _from,_to = name.split('/')\n",
    "        rates = rates + [{'to':_to,'price' : float(dt['price'])  }]\n",
    "    \n",
    "    return pd.DataFrame.from_records(rates)\n",
    "\n",
    "def get_price(code,data):\n",
    "    return data[data.to == code ].price\n",
    "# data frame from dictionary list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data normalization\n",
    "the goal price is represented using many currencies. we convert all the currrency to US Dollars by grabbing exchange rate from Yahoo and diving all currencies  by it's exhange rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_price(data,ex_data):\n",
    "    for index,dt in data.iterrows():\n",
    "        price = float(dt['goal']) / get_price(dt['currency'],ex_data) \n",
    "        data.set_value(index,'goal',price)\n",
    "    print('price normalization complete')\n",
    "    return data\n",
    "\n",
    "#modification to project name and description\n",
    "def get_ratio(name):\n",
    "    sc = 1\n",
    "    ab = 1\n",
    "    for c in name:\n",
    "        if c.isalpha():\n",
    "            ab += 1\n",
    "        else:\n",
    "            sc += 1\n",
    "    return sc/ab\n",
    "            \n",
    "\n",
    "def normalize_name_and_desc(data):\n",
    "    for index,dt in data.iterrows():\n",
    "        name_ratio = get_ratio(str(dt['name']))\n",
    "        desc_ratio = get_ratio(str(dt['desc']))\n",
    "        data.set_value(index,'name',name_ratio)\n",
    "        data.set_value(index,'desc',desc_ratio)\n",
    "    print('name and desc normalization complete')\n",
    "    return data\n",
    "    \n",
    "def normalize_deadline(data):\n",
    "    for index,dt in data.iterrows():\n",
    "        deadline = dt['deadline'] - dt['launched_at']\n",
    "        data.set_value(index,'deadline',deadline)\n",
    "    print('deadline normalization complete')\n",
    "    return data\n",
    "    \n",
    "def normalize(data,ex_data):\n",
    "    #data = normalize_deadline(data)\n",
    "    #data = normalize_name_and_desc(data)\n",
    "    data = normalize_price(data,ex_data)\n",
    "    return data\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train data\n",
      "replaced 'false' with False and 'true' with True\n",
      "errors fixed\n",
      "read exchange rates json\n",
      "dataframe is made from json data\n",
      "deadline normalization complete\n",
      "name and desc normalization complete\n",
      "price normalization complete\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "work flow : \n",
    " 1. Read training data\n",
    " 2. fix_errors\n",
    " 3. Read exchange rates json\n",
    " 4. Get dataframe of exchange rates\n",
    " 5. Normalize\n",
    " \n",
    "'''\n",
    "train_data = read_train_data()\n",
    "print('read train data')\n",
    "train_data = fix_errors(train_data)\n",
    "print('errors fixed')\n",
    "ex_rates = read_exchange_rates_json()\n",
    "print('read exchange rates json')\n",
    "ex_rates = get_exchange_rates_dataframe(ex_rates)\n",
    "print('dataframe is generated from json data')\n",
    "train_data = normalize(train_data,ex_rates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making lists\n",
      "names\n",
      "description\n",
      "goal\n",
      "disable communication\n",
      "deadline\n",
      "backers\n",
      "list imported\n",
      "array created\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "\n",
    "\n",
    "\n",
    "# print('making lists')\n",
    "# names  = train_data['name'].tolist()\n",
    "# _name = tf.contrib.layers.real_valued_column(\"name\")\n",
    "# print('names')\n",
    "# desc   = train_data['desc'].tolist()\n",
    "# _desc = tf.contrib.layers.real_valued_column(\"desc\")\n",
    "\n",
    "print('description')\n",
    "goal   = train_data['goal'].tolist()\n",
    "_goal = tf.contrib.layers.real_valued_column(\"goal\")\n",
    "\n",
    "print('goal')\n",
    "dis    = train_data['disable_communication'].tolist()\n",
    "_dis = tf.contrib.layers.real_valued_column(\"discomm\")\n",
    "\n",
    "print('disable communication')\n",
    "dead   = train_data['deadline'].tolist()\n",
    "_dead = tf.contrib.layers.real_valued_column(\"deadline\")\n",
    "\n",
    "print('deadline')\n",
    "bac    = train_data['backers_count'].tolist()\n",
    "_bac = tf.contrib.layers.real_valued_column(\"backers\")\n",
    "\n",
    "print('backers')\n",
    "\n",
    "length = len(names)\n",
    "steps  = length\n",
    "all_xs     = []\n",
    "print('list imported')\n",
    "\n",
    "for i in range(0,length):\n",
    "    all_xs.append([goal[i],dis[i],dead[i],bac[i]])\n",
    "all_ys = train_data['final_status'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "print('array created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn import datasets, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace True , False with 1,0\n",
    "for i in range(len(all_xs)):\n",
    "    if all_xs[i][1] == True:\n",
    "        all_xs[i][1] = 1\n",
    "    elif all_xs[i][1] == False:\n",
    "        all_xs[i][1] = 0\n",
    "day = 60 * 60 * 60 * 24\n",
    "# converts seconds into days\n",
    "for i in range(len(all_xs)):\n",
    "    all_xs[i][2] = all_xs[i][2]/day\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training data\n",
    "#x\n",
    "target = np.array(all_ys)\n",
    "#y\n",
    "data = np.array(all_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tensorflow linear classifier \n",
    "classifier = skflow.LinearClassifier(feature_columns=[tf.contrib.layers.real_valued_column(\"\", dimension=6)],\n",
    "                                     n_classes = 4,\n",
    "                                     optimizer=tf.train.FtrlOptimizer(\n",
    "                                                  learning_rate=0.05,\n",
    "                                                  l1_regularization_strength=0.001\n",
    "                                                ),\n",
    "                                     model_dir = './tmp'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-cbd14b6def98>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-20-cbd14b6def98>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tmp/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 1.38662\n",
      "INFO:tensorflow:global_step/sec: 3.97939\n",
      "INFO:tensorflow:step = 101, loss = 4.69274 (25.131 sec)\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "#remove existing data\n",
    "shutil.rmtree('./tmp')\n",
    "\n",
    "classifier.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
